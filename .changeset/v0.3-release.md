---
"gannicus": minor
"gannicus-cli": minor
---

feat: v0.3.0 - Multiple providers, benchmarks, and production-ready features

### Added
- **SGLang Provider** - High-performance self-hosted production inference (26k+ tokens/sec, Linux/CUDA)
- **MLX Provider** - Apple Silicon optimized inference leveraging Metal GPU (macOS M1/M2/M3/M4)
- **vLLM Provider** - High-performance inference runtime for Linux/CUDA servers (120-160 req/sec)
- **Hybrid Generation Types** - Type definitions for cost-effective massive dataset generation (Seed + Expand, Multi-Tenant, Time-Series)
- **End-to-End Tests** - Comprehensive E2E tests for all providers
- **Benchmark Suite** - Provider comparison and quick test scripts with automatic server management
- **Production Examples** - Complete examples for SGLang, MLX, and vLLM
- **Multi-Provider Comparison** - Example demonstrating all providers side-by-side
- **Benchmark Documentation** - Complete guide for running benchmarks
- **macOS Inference Runtimes Documentation** - Guide for Apple Silicon users

### Changed
- Updated provider support to include SGLang, MLX, and vLLM
- Enhanced generator to support multiple providers seamlessly
- Improved error handling with timeouts (60-120s) and better error messages
- Optimized batch sizes per provider (SGLang: 50, MLX: 30, vLLM: 50, Ollama: 5)
- Updated README with comprehensive provider documentation and examples
- Enhanced provider health checks with better model matching

### Fixed
- Provider availability detection across all platforms
- Model health checks for all providers with flexible matching
- Cross-platform compatibility (macOS, Linux, Windows with WSL2)
- Timeout handling to prevent hanging requests
- Error message truncation for better readability

